<!--
SPDX-FileCopyrightText: 2024 Idiap Research Institute <contact@idiap.ch>

SPDX-FileContributor: Pierre Vuillecard  <pierre.vuillecard@idiap.ch>

SPDX-License-Identifier: GPL-3.0-only
-->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Head Gesture Recognition</title>
    <style>
        body { 
            font-family: 'San Francisco', 'Helvetica Neue', Arial, sans-serif; 
            display: flex; 
            flex-direction: column; 
            align-items: center; 
            justify-content: flex-start;
            background-color: #f5f5f7;
            height: 100vh;
            margin: 0;
            padding: 0;
        }
        h1 {
            margin-top: 30px;
            font-size: 28px;
            font-weight: 600;
            color: #333;
        }
        .container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: 20px;
            flex-direction: column;
        }
        video {
            border-radius: 20px;
            margin-bottom: 30px;  /* Adjusted for more space for GIFs */
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.1);
            width: 640px;  /* Adjusted size for better layout */
            height: 480px;
            background-color: transparent; /* Remove white box */
        }
        #gifContainer {
            display: flex; 
            justify-content: center;  /* Center the GIFs */
            align-items: center;
            flex-wrap: nowrap;
            overflow: hidden;  /* Prevent scrolling */
            width: 80%;  /* Adjusted width for a more compact look */
            padding: 10px;
            border-radius: 20px;
            background-color: transparent; /* Remove white box */
        }
        .gifItem {
            margin: 0 20px;  /* Increased margin for better spacing */
            text-align: center;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .gifItem img {
            width: auto;
            height: 100px;  /* Slightly larger for better visibility */
            border-radius: 12px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);  /* Softer shadow for Apple-like refinement */
            object-fit: contain;
        }
        .gestureLabel {
            font-size: 16px;
            font-weight: 500;
            margin-bottom: 8px;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>Head Gesture Recognition</h1>

    <div class="container">
        <!-- Webcam stream -->
        <video id="webcam" autoplay></video>
    </div>

    <!-- GIF container at the bottom -->
    <div id="gifContainer"></div>

    <script>
        const videoElement = document.getElementById('webcam');
        const gifContainer = document.getElementById('gifContainer');
        const canvas = document.createElement('canvas');
        const context = canvas.getContext('2d');
        let lastGifUrl = '';  // Store the last GIF URL to prevent duplicates
        canvas.width = 640;
        canvas.height = 480;

        // Access the user's webcam
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                videoElement.srcObject = stream;
                videoElement.play();
            })
            .catch(err => {
                console.error("Error accessing the webcam: ", err);
            });

        // Capture and send frame every 66ms (~15 FPS)
        function captureAndSendFrame() {
            context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);  // Draw the video frame on the canvas
            canvas.toBlob(blob => {
                const timestamp = Date.now();
                sendFrameToBackend(blob, timestamp);
            }, 'image/jpeg');
        }

        // Send frame and timestamp to the backend
        function sendFrameToBackend(blob, timestamp) {
            const formData = new FormData();
            formData.append('frame', blob, 'frame.jpg');
            formData.append('timestamp', timestamp);

            fetch('/receive_frame', {  // Backend endpoint to receive each frame
                method: 'POST',
                body: formData
            })
            .then(response => response.json())  // Expect JSON response with GIF URL and gesture name
            .then(data => {
                // Check if gif_url exists and is not a duplicate
                if (data.gif_url && data.gesture_name && data.gif_url !== lastGifUrl) {
                    addGifToContainer(data.gif_url, data.gesture_name);  // Display the GIF and its gesture name
                    lastGifUrl = data.gif_url;  // Update the last GIF URL to prevent duplicates
                }
            })
            .catch(error => {
                console.error('Error sending frame to backend:', error);
            });
        }

        // Add the generated GIF and gesture name to the bottom of the page
        function addGifToContainer(gifUrl, gestureName) {
            const gifItem = document.createElement('div');
            gifItem.classList.add('gifItem');

            // Add gesture name above the GIF
            const labelElement = document.createElement('div');
            labelElement.classList.add('gestureLabel');
            labelElement.innerText = gestureName;

            const imgElement = document.createElement('img');
            imgElement.src = gifUrl;  // Load the GIF from the URL

            gifItem.appendChild(labelElement);  // Add gesture label
            gifItem.appendChild(imgElement);  // Add the GIF itself
            gifContainer.appendChild(gifItem);

            // Ensure only the latest 5 GIFs are displayed
            if (gifContainer.children.length > 5) {
                gifContainer.removeChild(gifContainer.firstChild);  // Remove the oldest GIF
            }
        }

        // Start capturing and sending frames every 66ms (~15 FPS)
        setInterval(captureAndSendFrame, 100);
    </script>
</body>
</html>
